@article{Angiulli2007338,
 abstract = {In this work, PFCNN, a distributed method for computing a consistent subset of very large data sets for the nearest neighbor decision rule is presented. In order to cope with the communication overhead typical of distributed environments and to reduce memory requirements, different variants of the basic PFCNN method are introduced. Experimental results, performed on a class of synthetic datasets revealed that these methods can be profitably applied to enormous collections of data. Indeed, they scale-up well and are efficient in memory consumption and achieve noticeable data reduction and good classification accuracy. To the best of our knowledge, this is the first distributed algorithm for computing a training set consistent subset for the nearest neighbor rule. © Springer-Verlag Berlin Heidelberg 2007.},
 author = {Angiulli, Fabrizio and Folino, Gianluigi},
 doi = {10.1007/978-3-540-74466-5_37},
 journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
 pages = {338 – 347},
 title = {Efficient distributed data condensation for nearest neighbor classification},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-38049123288&doi=10.1007%2f978-3-540-74466-5_37&partnerID=40&md5=6be34ac04eaeb896e4e08266243689f2},
 volume = {4641 LNCS},
 year = {2007}
}
